{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 Lab 5: RAG & Vector Databases for Banking\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand RAG architecture\n",
    "- Implement vector embeddings\n",
    "- Use FAISS vector database\n",
    "- Build banking knowledge base\n",
    "- Compare RAG vs Fine-tuning\n",
    "\n",
    "## üè¶ Banking Use Case\n",
    "Build a **Banking Policy Q&A System** using RAG to answer customer questions about loans, credit cards, and accounts.\n",
    "\n",
    "## ‚è±Ô∏è Duration: 45 minutes\n",
    "## üí∞ Cost: ~$0.15 (Bedrock API calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q faiss-cpu boto3 numpy pandas langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from typing import List, Dict\n",
    "import time\n",
    "\n",
    "# Initialize AWS clients\n",
    "bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create Banking Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banking policy documents\n",
    "banking_documents = [\n",
    "    {\n",
    "        \"id\": \"loan_policy_1\",\n",
    "        \"title\": \"Personal Loan Requirements\",\n",
    "        \"content\": \"\"\"SecureBank offers personal loans from $1,000 to $50,000. \n",
    "        Minimum credit score required is 650. Interest rates range from 6.5% to 12.5% APR \n",
    "        based on creditworthiness. Loan terms available: 12, 24, 36, 48, or 60 months. \n",
    "        Required documents: government-issued ID, proof of income (pay stubs or tax returns), \n",
    "        and recent bank statements.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"loan_policy_2\",\n",
    "        \"title\": \"Loan Approval Process\",\n",
    "        \"content\": \"\"\"The loan approval process takes 24-48 hours. Step 1: Submit online application. \n",
    "        Step 2: Credit check and income verification. Step 3: Loan officer review. \n",
    "        Step 4: Final approval and fund disbursement. Applicants must be 21-65 years old, \n",
    "        have minimum annual income of $30,000, and debt-to-income ratio below 40%.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"credit_card_1\",\n",
    "        \"title\": \"Credit Card Types\",\n",
    "        \"content\": \"\"\"SecureBank offers three credit card tiers: Classic Card ($500-$5,000 limit, \n",
    "        18.99% APR, no annual fee), Gold Card ($5,000-$15,000 limit, 15.99% APR, $95 annual fee), \n",
    "        and Platinum Card ($15,000-$50,000 limit, 12.99% APR, $195 annual fee). \n",
    "        All cards include fraud protection and 24/7 customer support.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"credit_card_2\",\n",
    "        \"title\": \"Credit Card Rewards\",\n",
    "        \"content\": \"\"\"Earn rewards on every purchase: 1% cashback on all purchases, \n",
    "        2% on groceries and gas, 3% on travel bookings. Gold and Platinum cards include \n",
    "        travel insurance, purchase protection, and extended warranty. No foreign transaction fees \n",
    "        on Platinum cards.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"savings_1\",\n",
    "        \"title\": \"Savings Account Types\",\n",
    "        \"content\": \"\"\"Three savings account options: Basic Savings (0.5% APY, $100 minimum balance), \n",
    "        High-Yield Savings (2.5% APY, $10,000 minimum), Premium Savings (3.5% APY, $50,000 minimum). \n",
    "        All accounts are FDIC insured up to $250,000. No monthly maintenance fees. \n",
    "        Interest compounded daily and credited monthly.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"savings_2\",\n",
    "        \"title\": \"Savings Account Features\",\n",
    "        \"content\": \"\"\"Free online and mobile banking with all savings accounts. \n",
    "        Nationwide ATM access. Automatic savings plans available. Federal regulation allows \n",
    "        up to 6 withdrawals per month. Unlimited deposits. No penalties for maintaining \n",
    "        minimum balance. Link to checking account for overdraft protection.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìö Created knowledge base with {len(banking_documents)} documents\")\n",
    "for doc in banking_documents:\n",
    "    print(f\"  - {doc['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Generate Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Generate vector embedding using Amazon Titan Embeddings\n",
    "    \"\"\"\n",
    "    body = json.dumps({\n",
    "        \"inputText\": text\n",
    "    })\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=\"amazon.titan-embed-text-v1\",\n",
    "        body=body\n",
    "    )\n",
    "    \n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body['embedding']\n",
    "\n",
    "# Generate embeddings for all documents\n",
    "print(\"üîÑ Generating embeddings...\")\n",
    "embeddings = []\n",
    "for doc in banking_documents:\n",
    "    embedding = get_embedding(doc['content'])\n",
    "    embeddings.append(embedding)\n",
    "    print(f\"  ‚úÖ {doc['title']}: {len(embedding)} dimensions\")\n",
    "\n",
    "# Convert to numpy array\n",
    "embeddings_array = np.array(embeddings).astype('float32')\n",
    "print(f\"\\nüìä Embeddings shape: {embeddings_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create FAISS Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index\n",
    "dimension = embeddings_array.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings_array)\n",
    "\n",
    "print(f\"‚úÖ FAISS index created\")\n",
    "print(f\"  Dimension: {dimension}\")\n",
    "print(f\"  Total vectors: {index.ntotal}\")\n",
    "print(f\"  Index type: L2 (Euclidean distance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Implement Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve top-k most relevant documents for a query\n",
    "    \"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = get_embedding(query)\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "    \n",
    "    # Search FAISS index\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    \n",
    "    # Retrieve documents\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            'document': banking_documents[idx],\n",
    "            'distance': float(distances[0][i]),\n",
    "            'rank': i + 1\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"What is the interest rate for personal loans?\"\n",
    "print(f\"üîç Query: {test_query}\\n\")\n",
    "\n",
    "results = retrieve_documents(test_query, top_k=3)\n",
    "for result in results:\n",
    "    print(f\"Rank {result['rank']}: {result['document']['title']}\")\n",
    "    print(f\"  Distance: {result['distance']:.4f}\")\n",
    "    print(f\"  Content: {result['document']['content'][:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Build RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(question: str, top_k: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve + Generate\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant documents\n",
    "    retrieved_docs = retrieve_documents(question, top_k)\n",
    "    \n",
    "    # Step 2: Create context from retrieved documents\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Document {r['rank']}: {r['document']['title']}\\n{r['document']['content']}\"\n",
    "        for r in retrieved_docs\n",
    "    ])\n",
    "    \n",
    "    # Step 3: Create prompt with context\n",
    "    prompt = f\"\"\"You are a helpful SecureBank customer service assistant. \n",
    "Use the following banking policy documents to answer the customer's question accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Customer Question: {question}\n",
    "\n",
    "Provide a clear, accurate answer based ONLY on the information in the documents. \n",
    "If the information is not available, say so. Include relevant details like rates, fees, or requirements.\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Step 4: Generate answer with Claude\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 500,\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    })\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        body=body\n",
    "    )\n",
    "    \n",
    "    response_body = json.loads(response['body'].read())\n",
    "    answer = response_body['content'][0]['text']\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'sources': [r['document']['title'] for r in retrieved_docs],\n",
    "        'retrieved_docs': retrieved_docs\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ RAG pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Test Banking Q&A System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions\n",
    "test_questions = [\n",
    "    \"What is the minimum credit score needed for a personal loan?\",\n",
    "    \"What are the benefits of the Platinum credit card?\",\n",
    "    \"How much interest do I earn on a High-Yield Savings account?\",\n",
    "    \"What documents do I need to apply for a loan?\",\n",
    "    \"Are there any monthly fees for savings accounts?\"\n",
    "]\n",
    "\n",
    "print(\"ü§ñ Testing Banking Q&A System\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n‚ùì Question {i}: {question}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    result = rag_query(question)\n",
    "    \n",
    "    print(f\"\\nüí¨ Answer:\\n{result['answer']}\")\n",
    "    print(f\"\\nüìö Sources: {', '.join(result['sources'])}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    time.sleep(1)  # Rate limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: RAG vs Fine-tuning Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {\n",
    "    \"Aspect\": [\n",
    "        \"Knowledge Updates\",\n",
    "        \"Training Required\",\n",
    "        \"Cost\",\n",
    "        \"Latency\",\n",
    "        \"Source Attribution\",\n",
    "        \"Accuracy\",\n",
    "        \"Maintenance\"\n",
    "    ],\n",
    "    \"RAG\": [\n",
    "        \"Real-time (just update docs)\",\n",
    "        \"No training needed\",\n",
    "        \"Low ($0.15 for this lab)\",\n",
    "        \"Higher (retrieval + generation)\",\n",
    "        \"Yes (can cite sources)\",\n",
    "        \"High (uses latest info)\",\n",
    "        \"Easy (update documents)\"\n",
    "    ],\n",
    "    \"Fine-tuning\": [\n",
    "        \"Requires retraining\",\n",
    "        \"Yes (hours/days)\",\n",
    "        \"High ($100-$1000+)\",\n",
    "        \"Lower (direct inference)\",\n",
    "        \"No (knowledge baked in)\",\n",
    "        \"High (for specific tasks)\",\n",
    "        \"Complex (retrain for updates)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(comparison)\n",
    "print(\"\\n‚öñÔ∏è RAG vs Fine-tuning Comparison:\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Decision Framework:\")\n",
    "print(\"  ‚úÖ Use RAG when:\")\n",
    "print(\"     - Knowledge changes frequently (policies, rates)\")\n",
    "print(\"     - Need source attribution\")\n",
    "print(\"     - Want low-cost solution\")\n",
    "print(\"     - Quick deployment needed\")\n",
    "print(\"\\n  ‚úÖ Use Fine-tuning when:\")\n",
    "print(\"     - Need specific output format\")\n",
    "print(\"     - Knowledge is stable\")\n",
    "print(\"     - Lower latency critical\")\n",
    "print(\"     - Domain-specific behavior needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: RAG Optimization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different chunk sizes\n",
    "def test_chunk_sizes():\n",
    "    print(\"üî¨ Testing Chunk Size Impact:\\n\")\n",
    "    \n",
    "    chunk_sizes = [100, 250, 500]\n",
    "    test_query = \"What credit score do I need?\"\n",
    "    \n",
    "    for size in chunk_sizes:\n",
    "        # Simulate chunking (simplified)\n",
    "        print(f\"Chunk size: {size} characters\")\n",
    "        print(f\"  Pros: {'More context' if size > 300 else 'More precise'}\")\n",
    "        print(f\"  Cons: {'Less precise' if size > 300 else 'Less context'}\")\n",
    "        print()\n",
    "\ntest_chunk_sizes()\n",
    "\n",
    "print(\"\\nüí° Optimization Tips:\")\n",
    "print(\"  1. Chunk size: 500-1000 characters (balance context vs precision)\")\n",
    "print(\"  2. Overlap: 10-20% between chunks\")\n",
    "print(\"  3. Top-k: 3-5 documents (more = more context but slower)\")\n",
    "print(\"  4. Embedding model: Titan (fast) vs Cohere (more accurate)\")\n",
    "print(\"  5. Reranking: Use cross-encoder for better relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Production Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè≠ Production RAG System Checklist:\\n\")\n",
    "\n",
    "checklist = {\n",
    "    \"Component\": [\n",
    "        \"Vector Database\",\n",
    "        \"Embedding Model\",\n",
    "        \"LLM\",\n",
    "        \"Document Store\",\n",
    "        \"Caching\",\n",
    "        \"Monitoring\",\n",
    "        \"Security\"\n",
    "    ],\n",
    "    \"Development\": [\n",
    "        \"FAISS (local)\",\n",
    "        \"Titan Embeddings\",\n",
    "        \"Claude Sonnet\",\n",
    "        \"Local files\",\n",
    "        \"None\",\n",
    "        \"Basic logging\",\n",
    "        \"IAM roles\"\n",
    "    ],\n",
    "    \"Production\": [\n",
    "        \"OpenSearch/Pinecone\",\n",
    "        \"Titan/Cohere\",\n",
    "        \"Claude Sonnet 4.5\",\n",
    "        \"S3 + versioning\",\n",
    "        \"ElastiCache\",\n",
    "        \"CloudWatch + X-Ray\",\n",
    "        \"VPC + encryption\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_prod = pd.DataFrame(checklist)\n",
    "print(df_prod.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí∞ Cost Estimates (1M queries/month):\")\n",
    "print(\"  Embeddings: $0.10 per 1M tokens\")\n",
    "print(\"  LLM (Claude): $3 per 1M input tokens\")\n",
    "print(\"  Vector DB: $50-200/month (OpenSearch)\")\n",
    "print(\"  Total: ~$300-500/month\")\n",
    "print(\"\\n  vs Fine-tuning: $1000+ one-time + retraining costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No cleanup needed - FAISS is in-memory\n",
    "print(\"‚úÖ No cleanup required (FAISS is in-memory)\")\n",
    "print(\"üí° In production, remember to:\")\n",
    "print(\"  - Delete OpenSearch domains when not in use\")\n",
    "print(\"  - Clean up S3 buckets\")\n",
    "print(\"  - Remove unused embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### RAG Architecture:\n",
    "1. **Retrieval**: Find relevant documents using vector similarity\n",
    "2. **Augmentation**: Add context to prompt\n",
    "3. **Generation**: LLM generates answer with context\n",
    "\n",
    "### Vector Databases:\n",
    "- **FAISS**: Fast, local, good for prototyping\n",
    "- **OpenSearch**: Production-ready, scalable, hybrid search\n",
    "- **Pinecone**: Fully managed, easy to use\n",
    "- **pgvector**: Good if already using PostgreSQL\n",
    "\n",
    "### When to Use RAG:\n",
    "- ‚úÖ Knowledge changes frequently\n",
    "- ‚úÖ Need source attribution\n",
    "- ‚úÖ Want low-cost solution\n",
    "- ‚úÖ Quick deployment needed\n",
    "- ‚úÖ Multiple knowledge sources\n",
    "\n",
    "### RAG vs Fine-tuning:\n",
    "- **RAG**: Real-time updates, lower cost, source attribution\n",
    "- **Fine-tuning**: Specific format, lower latency, frozen knowledge\n",
    "- **Hybrid**: Best of both (fine-tune for format, RAG for knowledge)\n",
    "\n",
    "### Production Best Practices:\n",
    "1. Use managed vector database (OpenSearch/Pinecone)\n",
    "2. Implement caching for common queries\n",
    "3. Monitor latency and accuracy\n",
    "4. Version your documents\n",
    "5. Implement fallback strategies\n",
    "6. Use reranking for better relevance\n",
    "7. Optimize chunk size and overlap\n",
    "\n",
    "### Banking Use Cases:\n",
    "- ‚úÖ Policy Q&A (this lab)\n",
    "- ‚úÖ Compliance document search\n",
    "- ‚úÖ Product recommendations\n",
    "- ‚úÖ Customer support automation\n",
    "- ‚úÖ Internal knowledge base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
