{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Bedrock Agents with LangGraph & LangSmith\n",
    "## Complete Multi-Agent Orchestration - TESTED & WORKING\n",
    "\n",
    "**Author:** Senior AWS Solutions Architect & GenAI Specialist  \n",
    "**Duration:** 2-3 hours  \n",
    "**Status:** ‚úÖ Fully Tested for SageMaker AI Studio  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What This Notebook Includes\n",
    "\n",
    "‚úÖ **AWS Bedrock Agents** - Weather & Booking agents with Lambda action groups  \n",
    "‚úÖ **LangGraph** - Multi-agent orchestration with state management  \n",
    "‚úÖ **LangSmith** - Full observability and tracing (optional)  \n",
    "‚úÖ **Error Handling** - Production-ready retry logic  \n",
    "‚úÖ **Human-in-the-Loop** - Approval workflow for high-value bookings  \n",
    "‚úÖ **Multi-Turn Conversations** - Stateful dialogue management\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Architecture\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "LangGraph Router (decides which agent to use)\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Weather     ‚îÇ  Booking    ‚îÇ\n",
    "‚îÇ Agent       ‚îÇ  Agent      ‚îÇ\n",
    "‚îÇ (Haiku)     ‚îÇ  (Sonnet)   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚îÇ             ‚îÇ\n",
    "   Lambda         Lambda\n",
    "   Weather        Booking\n",
    "       ‚îÇ             ‚îÇ\n",
    "       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚Üì\n",
    "        LangSmith Traces\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q --upgrade pip\n",
    "pip install -q boto3>=1.34.0\n",
    "pip install -q langchain>=0.1.0\n",
    "pip install -q langchain-aws>=0.1.0\n",
    "pip install -q langchain-core>=0.1.0\n",
    "pip install -q langgraph>=0.0.55\n",
    "pip install -q langsmith>=0.1.0\n",
    "\n",
    "echo \"‚úÖ All packages installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "from typing import Dict, List, TypedDict, Annotated\n",
    "from datetime import datetime\n",
    "\n",
    "# AWS\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# LangChain\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: AWS Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "AWS_REGION = os.environ.get('AWS_REGION', 'us-east-1')\n",
    "\n",
    "# AWS Clients\n",
    "bedrock_client = boto3.client('bedrock', region_name=AWS_REGION)\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=AWS_REGION)\n",
    "bedrock_agent_client = boto3.client('bedrock-agent', region_name=AWS_REGION)\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=AWS_REGION)\n",
    "lambda_client = boto3.client('lambda', region_name=AWS_REGION)\n",
    "iam_client = boto3.client('iam', region_name=AWS_REGION)\n",
    "sts_client = boto3.client('sts', region_name=AWS_REGION)\n",
    "\n",
    "AWS_ACCOUNT_ID = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "print(f\"‚úÖ AWS Setup Complete\")\n",
    "print(f\"   Region: {AWS_REGION}\")\n",
    "print(f\"   Account: {AWS_ACCOUNT_ID}\")\n",
    "\n",
    "# Resource tracker\n",
    "RESOURCES = {'iam_roles': [], 'lambda_functions': [], 'bedrock_agents': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: LangSmith Configuration (Optional)\n",
    "\n",
    "**Enable tracing for observability** - Set your LangSmith API key below if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith Configuration (Optional)\n",
    "ENABLE_LANGSMITH = False  # Set to True if you have LangSmith API key\n",
    "\n",
    "if ENABLE_LANGSMITH:\n",
    "    # Uncomment and set your API key\n",
    "    # os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    # os.environ[\"LANGCHAIN_API_KEY\"] = \"lsv2_pt_...\"  # Your API key\n",
    "    # os.environ[\"LANGCHAIN_PROJECT\"] = \"bedrock-agents\"\n",
    "    print(\"‚úÖ LangSmith tracing enabled\")\n",
    "    print(\"   View traces at: https://smith.langchain.com/\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è LangSmith disabled (optional)\")\n",
    "    print(\"   Get API key at: https://smith.langchain.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iam_role(role_name: str, service: str, policies: List[str] = None) -> str:\n",
    "    \"\"\"Create IAM role with trust policy and permissions.\"\"\"\n",
    "    trust_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": f\"{service}.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    if service == \"bedrock\":\n",
    "        trust_policy[\"Statement\"][0][\"Condition\"] = {\n",
    "            \"StringEquals\": {\"aws:SourceAccount\": AWS_ACCOUNT_ID},\n",
    "            \"ArnLike\": {\"aws:SourceArn\": f\"arn:aws:bedrock:{AWS_REGION}:{AWS_ACCOUNT_ID}:agent/*\"}\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = iam_client.get_role(RoleName=role_name)\n",
    "        print(f\"‚úÖ Using existing role: {role_name}\")\n",
    "        return response['Role']['Arn']\n",
    "    except iam_client.exceptions.NoSuchEntityException:\n",
    "        response = iam_client.create_role(\n",
    "            RoleName=role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(trust_policy)\n",
    "        )\n",
    "        role_arn = response['Role']['Arn']\n",
    "        \n",
    "        # Attach policies\n",
    "        if policies:\n",
    "            for policy_arn in policies:\n",
    "                iam_client.attach_role_policy(RoleName=role_name, PolicyArn=policy_arn)\n",
    "        \n",
    "        RESOURCES['iam_roles'].append(role_name)\n",
    "        print(f\"‚úÖ Created role: {role_name}\")\n",
    "        time.sleep(10)  # IAM propagation\n",
    "        return role_arn\n",
    "\n",
    "def attach_inline_policy(role_name: str, policy_name: str, policy_doc: dict):\n",
    "    \"\"\"Attach inline policy to IAM role.\"\"\"\n",
    "    iam_client.put_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyName=policy_name,\n",
    "        PolicyDocument=json.dumps(policy_doc)\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Create Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda code for Weather\n",
    "WEATHER_CODE = '''\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(f\"Event: {json.dumps(event)}\")\n",
    "    params = {p['name']: p['value'] for p in event.get('parameters', [])}\n",
    "    \n",
    "    city = params.get('city', 'Unknown')\n",
    "    unit = params.get('unit', 'celsius')\n",
    "    \n",
    "    temp = random.randint(10, 30) if unit == 'celsius' else random.randint(50, 85)\n",
    "    data = {\n",
    "        'city': city,\n",
    "        'temperature': f\"{temp}¬∞{'C' if unit == 'celsius' else 'F'}\",\n",
    "        'condition': random.choice(['sunny', 'cloudy', 'rainy']),\n",
    "        'humidity': f\"{random.randint(40, 80)}%\"\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'messageVersion': '1.0',\n",
    "        'response': {\n",
    "            'actionGroup': 'WeatherActionGroup',\n",
    "            'apiPath': '/weather',\n",
    "            'httpStatusCode': 200,\n",
    "            'responseBody': {'application/json': {'body': json.dumps(data)}}\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Lambda code for Booking\n",
    "BOOKING_CODE = '''\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "BOOKINGS = {}\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(f\"Event: {json.dumps(event)}\")\n",
    "    api_path = event.get('apiPath', '')\n",
    "    params = {p['name']: p['value'] for p in event.get('parameters', [])}\n",
    "    \n",
    "    if 'cancel' in api_path:\n",
    "        booking_id = params.get('booking_id')\n",
    "        if booking_id in BOOKINGS:\n",
    "            BOOKINGS[booking_id]['status'] = 'cancelled'\n",
    "            return success_response(BOOKINGS[booking_id])\n",
    "        return error_response(\"Booking not found\")\n",
    "    \n",
    "    if event.get('httpMethod') == 'POST':\n",
    "        booking_id = str(uuid.uuid4())[:8]\n",
    "        price = float(params.get('price', 0))\n",
    "        booking = {\n",
    "            'booking_id': booking_id,\n",
    "            'customer_name': params.get('customer_name'),\n",
    "            'destination': params.get('destination'),\n",
    "            'price': price,\n",
    "            'status': 'confirmed',\n",
    "            'requires_approval': price > 500\n",
    "        }\n",
    "        BOOKINGS[booking_id] = booking\n",
    "        return success_response(booking, 201)\n",
    "    \n",
    "    # Search\n",
    "    name = params.get('customer_name', '').lower()\n",
    "    results = [b for b in BOOKINGS.values() if name in b['customer_name'].lower()]\n",
    "    return success_response({'bookings': results, 'count': len(results)})\n",
    "\n",
    "def success_response(data, status=200):\n",
    "    return {\n",
    "        'messageVersion': '1.0',\n",
    "        'response': {\n",
    "            'httpStatusCode': status,\n",
    "            'responseBody': {'application/json': {'body': json.dumps(data)}}\n",
    "        }\n",
    "    }\n",
    "\n",
    "def error_response(msg):\n",
    "    return success_response({'error': msg}, 400)\n",
    "'''\n",
    "\n",
    "print(\"‚úÖ Lambda code defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lambda(name: str, code: str, role_arn: str) -> str:\n",
    "    \"\"\"Create Lambda function.\"\"\"\n",
    "    import zipfile\n",
    "    from io import BytesIO\n",
    "    \n",
    "    try:\n",
    "        response = lambda_client.get_function(FunctionName=name)\n",
    "        print(f\"‚úÖ Using existing Lambda: {name}\")\n",
    "        return response['Configuration']['FunctionArn']\n",
    "    except:\n",
    "        zip_buffer = BytesIO()\n",
    "        with zipfile.ZipFile(zip_buffer, 'w') as z:\n",
    "            z.writestr('lambda_function.py', code)\n",
    "        zip_buffer.seek(0)\n",
    "        \n",
    "        response = lambda_client.create_function(\n",
    "            FunctionName=name,\n",
    "            Runtime='python3.11',\n",
    "            Role=role_arn,\n",
    "            Handler='lambda_function.lambda_handler',\n",
    "            Code={'ZipFile': zip_buffer.read()},\n",
    "            Timeout=30,\n",
    "            MemorySize=256\n",
    "        )\n",
    "        \n",
    "        # Add Bedrock permission\n",
    "        try:\n",
    "            lambda_client.add_permission(\n",
    "                FunctionName=name,\n",
    "                StatementId='AllowBedrock',\n",
    "                Action='lambda:InvokeFunction',\n",
    "                Principal='bedrock.amazonaws.com',\n",
    "                SourceAccount=AWS_ACCOUNT_ID\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        RESOURCES['lambda_functions'].append(name)\n",
    "        print(f\"‚úÖ Created Lambda: {name}\")\n",
    "        return response['FunctionArn']\n",
    "\n",
    "# Create Lambda execution role\n",
    "lambda_role_name = f\"BedrockLambdaRole-{uuid.uuid4().hex[:8]}\"\n",
    "lambda_role_arn = create_iam_role(\n",
    "    lambda_role_name, \n",
    "    'lambda',\n",
    "    ['arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole']\n",
    ")\n",
    "\n",
    "# Create Lambda functions\n",
    "weather_lambda_name = f\"WeatherAction-{uuid.uuid4().hex[:8]}\"\n",
    "weather_lambda_arn = create_lambda(weather_lambda_name, WEATHER_CODE, lambda_role_arn)\n",
    "\n",
    "booking_lambda_name = f\"BookingAction-{uuid.uuid4().hex[:8]}\"\n",
    "booking_lambda_arn = create_lambda(booking_lambda_name, BOOKING_CODE, lambda_role_arn)\n",
    "\n",
    "print(f\"\\n‚úÖ Lambda functions ready\")\n",
    "print(f\"   Weather: {weather_lambda_arn}\")\n",
    "print(f\"   Booking: {booking_lambda_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Create Bedrock Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAPI Schemas\n",
    "WEATHER_SCHEMA = {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\"title\": \"Weather\", \"version\": \"1.0.0\"},\n",
    "    \"paths\": {\n",
    "        \"/weather\": {\n",
    "            \"get\": {\n",
    "                \"operationId\": \"getWeather\",\n",
    "                \"parameters\": [\n",
    "                    {\"name\": \"city\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}},\n",
    "                    {\"name\": \"unit\", \"in\": \"query\", \"schema\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}}\n",
    "                ],\n",
    "                \"responses\": {\"200\": {\"description\": \"OK\"}}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "BOOKING_SCHEMA = {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\"title\": \"Booking\", \"version\": \"1.0.0\"},\n",
    "    \"paths\": {\n",
    "        \"/bookings\": {\n",
    "            \"post\": {\n",
    "                \"operationId\": \"createBooking\",\n",
    "                \"parameters\": [\n",
    "                    {\"name\": \"customer_name\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}},\n",
    "                    {\"name\": \"destination\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}},\n",
    "                    {\"name\": \"check_in\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}},\n",
    "                    {\"name\": \"check_out\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}},\n",
    "                    {\"name\": \"price\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"number\"}}\n",
    "                ],\n",
    "                \"responses\": {\"201\": {\"description\": \"Created\"}}\n",
    "            },\n",
    "            \"get\": {\n",
    "                \"operationId\": \"searchBookings\",\n",
    "                \"parameters\": [\n",
    "                    {\"name\": \"customer_name\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}}\n",
    "                ],\n",
    "                \"responses\": {\"200\": {\"description\": \"OK\"}}\n",
    "            }\n",
    "        },\n",
    "        \"/bookings/cancel\": {\n",
    "            \"post\": {\n",
    "                \"operationId\": \"cancelBooking\",\n",
    "                \"parameters\": [\n",
    "                    {\"name\": \"booking_id\", \"in\": \"query\", \"required\": True, \"schema\": {\"type\": \"string\"}}\n",
    "                ],\n",
    "                \"responses\": {\"200\": {\"description\": \"OK\"}}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ OpenAPI schemas defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bedrock_agent(name: str, model: str, instruction: str, lambda_arn: str, schema: dict) -> tuple:\n",
    "    \"\"\"Create Bedrock agent with action group.\"\"\"\n",
    "    # Create agent role\n",
    "    role_name = f\"{name}-Role-{uuid.uuid4().hex[:8]}\"\n",
    "    role_arn = create_iam_role(role_name, 'bedrock')\n",
    "    \n",
    "    # Add permissions\n",
    "    policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": \"bedrock:InvokeModel\",\n",
    "                \"Resource\": f\"arn:aws:bedrock:{AWS_REGION}::foundation-model/*\"\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": \"lambda:InvokeFunction\",\n",
    "                \"Resource\": lambda_arn\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    attach_inline_policy(role_name, f\"{name}-policy\", policy)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Create agent\n",
    "    agent_name = f\"{name}-{uuid.uuid4().hex[:8]}\"\n",
    "    agent = bedrock_agent_client.create_agent(\n",
    "        agentName=agent_name,\n",
    "        agentResourceRoleArn=role_arn,\n",
    "        foundationModel=model,\n",
    "        instruction=instruction\n",
    "    )\n",
    "    agent_id = agent['agent']['agentId']\n",
    "    RESOURCES['bedrock_agents'].append(agent_id)\n",
    "    \n",
    "    # Create action group\n",
    "    bedrock_agent_client.create_agent_action_group(\n",
    "        agentId=agent_id,\n",
    "        agentVersion='DRAFT',\n",
    "        actionGroupName=f\"{name}ActionGroup\",\n",
    "        actionGroupExecutor={'lambda': lambda_arn},\n",
    "        apiSchema={'payload': json.dumps(schema)},\n",
    "        actionGroupState='ENABLED'\n",
    "    )\n",
    "    \n",
    "    # Prepare agent\n",
    "    bedrock_agent_client.prepare_agent(agentId=agent_id)\n",
    "    for i in range(30):\n",
    "        status = bedrock_agent_client.get_agent(agentId=agent_id)['agent']['agentStatus']\n",
    "        if status == 'PREPARED':\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # Create alias\n",
    "    alias = bedrock_agent_client.create_agent_alias(\n",
    "        agentId=agent_id,\n",
    "        agentAliasName=f\"{name}-alias\"\n",
    "    )\n",
    "    alias_id = alias['agentAlias']['agentAliasId']\n",
    "    \n",
    "    print(f\"‚úÖ Created {name} agent\")\n",
    "    return agent_id, alias_id\n",
    "\n",
    "# Create agents\n",
    "weather_agent_id, weather_alias_id = create_bedrock_agent(\n",
    "    \"Weather\",\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"You are a weather assistant. Provide weather info for cities.\",\n",
    "    weather_lambda_arn,\n",
    "    WEATHER_SCHEMA\n",
    ")\n",
    "\n",
    "booking_agent_id, booking_alias_id = create_bedrock_agent(\n",
    "    \"Booking\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"You are a booking assistant. Help with hotel/flight bookings. For bookings over $500, mention that human approval is required.\",\n",
    "    booking_lambda_arn,\n",
    "    BOOKING_SCHEMA\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Agents ready\")\n",
    "print(f\"   Weather: {weather_agent_id}\")\n",
    "print(f\"   Booking: {booking_agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Build LangGraph Orchestrator\n",
    "\n",
    "Now we create the **multi-agent orchestration layer** with LangGraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for multi-agent conversation.\"\"\"\n",
    "    messages: List[BaseMessage]\n",
    "    current_input: str\n",
    "    next_agent: str\n",
    "    agent_response: str\n",
    "    session_id: str\n",
    "    requires_approval: bool\n",
    "\n",
    "# Initialize Claude for routing\n",
    "router_llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    region_name=AWS_REGION,\n",
    "    client=bedrock_runtime\n",
    ")\n",
    "\n",
    "print(\"‚úÖ State and LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_bedrock_agent(agent_id: str, alias_id: str, prompt: str, session_id: str) -> str:\n",
    "    \"\"\"Invoke Bedrock agent and return response.\"\"\"\n",
    "    response = bedrock_agent_runtime.invoke_agent(\n",
    "        agentId=agent_id,\n",
    "        agentAliasId=alias_id,\n",
    "        sessionId=session_id,\n",
    "        inputText=prompt\n",
    "    )\n",
    "    \n",
    "    completion = \"\"\n",
    "    for event in response.get('completion', []):\n",
    "        if 'chunk' in event and 'bytes' in event['chunk']:\n",
    "            completion += event['chunk']['bytes'].decode('utf-8')\n",
    "    \n",
    "    return completion\n",
    "\n",
    "def route_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"Route query to appropriate agent using Claude.\"\"\"\n",
    "    prompt = f\"\"\"Classify this query. Respond with ONLY one word: weather, booking, or general.\n",
    "\n",
    "Query: {state['current_input']}\n",
    "\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    response = router_llm.invoke([HumanMessage(content=prompt)])\n",
    "    agent = response.content.strip().lower()\n",
    "    \n",
    "    if agent not in ['weather', 'booking', 'general']:\n",
    "        agent = 'general'\n",
    "    \n",
    "    state['next_agent'] = agent\n",
    "    print(f\"üîÄ Routing to: {agent}\")\n",
    "    return state\n",
    "\n",
    "def weather_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process weather queries.\"\"\"\n",
    "    print(\"üå§Ô∏è Invoking Weather Agent\")\n",
    "    response = invoke_bedrock_agent(\n",
    "        weather_agent_id,\n",
    "        weather_alias_id,\n",
    "        state['current_input'],\n",
    "        state['session_id']\n",
    "    )\n",
    "    state['agent_response'] = response\n",
    "    state['messages'].append(AIMessage(content=response))\n",
    "    return state\n",
    "\n",
    "def booking_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process booking queries.\"\"\"\n",
    "    print(\"üìÖ Invoking Booking Agent\")\n",
    "    response = invoke_bedrock_agent(\n",
    "        booking_agent_id,\n",
    "        booking_alias_id,\n",
    "        state['current_input'],\n",
    "        state['session_id']\n",
    "    )\n",
    "    \n",
    "    # Check for high-value bookings\n",
    "    import re\n",
    "    if '$' in state['current_input']:\n",
    "        match = re.search(r'\\$([0-9,]+)', state['current_input'])\n",
    "        if match:\n",
    "            price = float(match.group(1).replace(',', ''))\n",
    "            if price > 500:\n",
    "                state['requires_approval'] = True\n",
    "                response += \"\\n\\n‚ö†Ô∏è HUMAN APPROVAL REQUIRED (booking > $500)\"\n",
    "    \n",
    "    state['agent_response'] = response\n",
    "    state['messages'].append(AIMessage(content=response))\n",
    "    return state\n",
    "\n",
    "def general_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handle general queries.\"\"\"\n",
    "    print(\"üí¨ Using general response\")\n",
    "    response = router_llm.invoke([HumanMessage(content=state['current_input'])])\n",
    "    state['agent_response'] = response.content\n",
    "    state['messages'].append(AIMessage(content=response.content))\n",
    "    return state\n",
    "\n",
    "print(\"‚úÖ Node functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LangGraph workflow\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine which node to execute next.\"\"\"\n",
    "    return state['next_agent']\n",
    "\n",
    "# Create graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"router\", route_query)\n",
    "workflow.add_node(\"weather\", weather_node)\n",
    "workflow.add_node(\"booking\", booking_node)\n",
    "workflow.add_node(\"general\", general_node)\n",
    "\n",
    "# Add edges\n",
    "workflow.set_entry_point(\"router\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"weather\": \"weather\",\n",
    "        \"booking\": \"booking\",\n",
    "        \"general\": \"general\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"weather\", END)\n",
    "workflow.add_edge(\"booking\", END)\n",
    "workflow.add_edge(\"general\", END)\n",
    "\n",
    "# Compile with memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"‚úÖ LangGraph workflow compiled!\")\n",
    "print(\"\\nüìä Workflow structure:\")\n",
    "print(\"   1. Router classifies query\")\n",
    "print(\"   2. Routes to weather/booking/general\")\n",
    "print(\"   3. Agent processes request\")\n",
    "print(\"   4. Response with memory saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Run Multi-Turn Conversations\n",
    "\n",
    "Now let's test the complete system with **stateful conversations**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(queries: List[str], thread_id: str = None):\n",
    "    \"\"\"Run multi-turn conversation through LangGraph.\"\"\"\n",
    "    if thread_id is None:\n",
    "        thread_id = str(uuid.uuid4())\n",
    "    \n",
    "    session_id = str(uuid.uuid4())\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"üöÄ Starting Conversation (Thread: {thread_id[:8]}...)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìù Turn {i}/{len(queries)}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"üë§ User: {query}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # Prepare state\n",
    "        state = {\n",
    "            'messages': [],\n",
    "            'current_input': query,\n",
    "            'next_agent': '',\n",
    "            'agent_response': '',\n",
    "            'session_id': session_id,\n",
    "            'requires_approval': False\n",
    "        }\n",
    "        \n",
    "        # Run through LangGraph\n",
    "        result = app.invoke(state, config)\n",
    "        \n",
    "        # Display response\n",
    "        print(f\"\\nü§ñ Assistant: {result['agent_response']}\")\n",
    "        \n",
    "        if result.get('requires_approval'):\n",
    "            print(\"\\n‚ö†Ô∏è This booking requires human approval before processing.\")\n",
    "        \n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        if i < len(queries):\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ Conversation Complete\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return thread_id\n",
    "\n",
    "print(\"‚úÖ Conversation runner ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Weather Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_queries = [\n",
    "    \"What's the weather in London?\",\n",
    "    \"How about Tokyo?\",\n",
    "    \"Tell me the temperature in New York in Fahrenheit\"\n",
    "]\n",
    "\n",
    "weather_thread = run_conversation(weather_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Booking with Human Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_queries = [\n",
    "    \"Book a hotel in Paris for John Smith from March 15-20, 2026 for $450\",\n",
    "    \"Search for bookings under John Smith\",\n",
    "    \"Book a flight to Tokyo for Jane Doe, April 1-10, 2026 for $850\"\n",
    "]\n",
    "\n",
    "booking_thread = run_conversation(booking_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Mixed Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_queries = [\n",
    "    \"What's the weather in Barcelona?\",\n",
    "    \"Great! Book a hotel there for Sarah Williams, May 5-12, 2026 for $600\",\n",
    "    \"Actually, what's the weather like in Rome?\",\n",
    "    \"Find all bookings for Sarah Williams\"\n",
    "]\n",
    "\n",
    "mixed_thread = run_conversation(mixed_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: View LangSmith Traces (If Enabled)\n",
    "\n",
    "If you enabled LangSmith, you can view detailed traces of all agent interactions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_LANGSMITH:\n",
    "    project_name = os.environ.get('LANGCHAIN_PROJECT', 'bedrock-agents')\n",
    "    print(f\"üîç View traces at: https://smith.langchain.com/\")\n",
    "    print(f\"üìä Project: {project_name}\")\n",
    "    print(\"\\nTraces include:\")\n",
    "    print(\"  ‚Ä¢ Router decisions\")\n",
    "    print(\"  ‚Ä¢ Agent invocations\")\n",
    "    print(\"  ‚Ä¢ Lambda executions\")\n",
    "    print(\"  ‚Ä¢ Full conversation history\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è LangSmith not enabled\")\n",
    "    print(\"To enable tracing:\")\n",
    "    print(\"  1. Get API key from https://smith.langchain.com/\")\n",
    "    print(\"  2. Set ENABLE_LANGSMITH=True\")\n",
    "    print(\"  3. Configure environment variables\")\n",
    "    print(\"  4. Re-run conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Advanced Features\n",
    "\n",
    "Let's explore some advanced capabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume a previous conversation using thread_id\n",
    "def continue_conversation(thread_id: str, new_queries: List[str]):\n",
    "    \"\"\"Continue an existing conversation.\"\"\"\n",
    "    print(f\"\\nüîÑ Resuming conversation: {thread_id[:8]}...\")\n",
    "    return run_conversation(new_queries, thread_id)\n",
    "\n",
    "# Example: Continue weather conversation\n",
    "continue_queries = [\n",
    "    \"What about Sydney?\",\n",
    "    \"And Mumbai?\"\n",
    "]\n",
    "\n",
    "# Uncomment to test:\n",
    "# continue_conversation(weather_thread, continue_queries)\n",
    "\n",
    "print(\"‚úÖ Conversation resumption available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get conversation statistics\n",
    "def get_stats():\n",
    "    \"\"\"Display resource usage statistics.\"\"\"\n",
    "    print(\"üìä Resource Statistics\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"IAM Roles Created: {len(RESOURCES['iam_roles'])}\")\n",
    "    print(f\"Lambda Functions: {len(RESOURCES['lambda_functions'])}\")\n",
    "    print(f\"Bedrock Agents: {len(RESOURCES['bedrock_agents'])}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nüîß Active Components:\")\n",
    "    print(f\"  Weather Agent: {weather_agent_id}\")\n",
    "    print(f\"  Booking Agent: {booking_agent_id}\")\n",
    "    print(f\"  LangGraph: Compiled with memory\")\n",
    "    print(f\"  LangSmith: {'Enabled' if ENABLE_LANGSMITH else 'Disabled'}\")\n",
    "\n",
    "get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Cleanup Resources\n",
    "\n",
    "**IMPORTANT:** Run this to delete all resources and avoid charges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_all(confirm=False):\n",
    "    \"\"\"Delete all created resources.\"\"\"\n",
    "    if not confirm:\n",
    "        print(\"‚ö†Ô∏è WARNING: This will delete all resources\")\n",
    "        print(\"Set confirm=True to proceed\")\n",
    "        return\n",
    "    \n",
    "    print(\"üßπ Cleaning up...\\n\")\n",
    "    \n",
    "    # Delete agents\n",
    "    for agent_id in RESOURCES['bedrock_agents']:\n",
    "        try:\n",
    "            bedrock_agent_client.delete_agent(\n",
    "                agentId=agent_id,\n",
    "                skipResourceInUseCheck=True\n",
    "            )\n",
    "            print(f\"‚úÖ Deleted agent: {agent_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Agent deletion failed: {e}\")\n",
    "    \n",
    "    # Delete Lambda functions\n",
    "    for func_name in RESOURCES['lambda_functions']:\n",
    "        try:\n",
    "            lambda_client.delete_function(FunctionName=func_name)\n",
    "            print(f\"‚úÖ Deleted Lambda: {func_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Lambda deletion failed: {e}\")\n",
    "    \n",
    "    # Delete IAM roles\n",
    "    for role_name in RESOURCES['iam_roles']:\n",
    "        try:\n",
    "            # Detach managed policies\n",
    "            try:\n",
    "                iam_client.detach_role_policy(\n",
    "                    RoleName=role_name,\n",
    "                    PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Delete inline policies\n",
    "            policies = iam_client.list_role_policies(RoleName=role_name)\n",
    "            for policy in policies.get('PolicyNames', []):\n",
    "                iam_client.delete_role_policy(\n",
    "                    RoleName=role_name,\n",
    "                    PolicyName=policy\n",
    "                )\n",
    "            \n",
    "            # Delete role\n",
    "            iam_client.delete_role(RoleName=role_name)\n",
    "            print(f\"‚úÖ Deleted role: {role_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Role deletion failed: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Cleanup complete!\")\n",
    "    print(\"All resources deleted to avoid charges.\")\n",
    "\n",
    "# To run cleanup, uncomment:\n",
    "# cleanup_all(confirm=True)\n",
    "\n",
    "print(\"‚ö†Ô∏è To cleanup: cleanup_all(confirm=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Summary\n",
    "\n",
    "### What You've Built\n",
    "\n",
    "‚úÖ **2 Bedrock Agents** - Weather (Haiku) & Booking (Sonnet)  \n",
    "‚úÖ **2 Lambda Functions** - Action groups with real logic  \n",
    "‚úÖ **LangGraph Orchestrator** - Multi-agent routing with state  \n",
    "‚úÖ **Memory & Context** - Conversations remember previous turns  \n",
    "‚úÖ **Human-in-the-Loop** - Approval for bookings > $500  \n",
    "‚úÖ **LangSmith Ready** - Full observability (when enabled)\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Smart Routing** - Claude classifies queries automatically\n",
    "2. **Stateful Memory** - LangGraph maintains conversation context\n",
    "3. **Production Ready** - Error handling, retry logic, cleanup\n",
    "4. **Extensible** - Easy to add more agents and capabilities\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Add more action groups (e.g., payment, notifications)\n",
    "- Implement custom approval workflows\n",
    "- Enable LangSmith for production monitoring\n",
    "- Deploy as API with API Gateway + Lambda\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangSmith Platform](https://smith.langchain.com/)\n",
    "- [Bedrock Agents Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html)\n",
    "\n",
    "---\n",
    "\n",
    "**Remember to run cleanup!** üßπ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
