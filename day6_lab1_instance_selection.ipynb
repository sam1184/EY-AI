{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 Lab 1: Instance Selection & Cost Optimization\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand T-series vs M-series instances\n",
    "- Compare costs and performance\n",
    "- Monitor CloudWatch metrics\n",
    "- Make informed instance selection decisions\n",
    "\n",
    "## üè¶ Banking Use Case\n",
    "Deploy a **credit risk scoring model** on different instance types to find optimal cost/performance balance.\n",
    "\n",
    "## ‚è±Ô∏è Duration: 30 minutes\n",
    "## üí∞ Cost: ~$0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Initialize\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Deploy Model on ml.t3.medium (Endpoint Only)\n",
    "\n",
    "**Key Learning:** T-series instances can ONLY be used for endpoints, NOT training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pre-trained model from Day 5\n",
    "model_data = f\"s3://{bucket}/sagemaker/credit-risk-model/model.tar.gz\"\n",
    "\n",
    "# Create model\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    framework_version='1.0-1',\n",
    "    py_version='py3'\n",
    ")\n",
    "\n",
    "# Deploy to T3 endpoint\n",
    "t3_endpoint_name = f\"credit-risk-t3-{int(time.time())}\"\n",
    "print(f\"Deploying to {t3_endpoint_name}...\")\n",
    "\n",
    "t3_predictor = sklearn_model.deploy(\n",
    "    instance_type='ml.t3.medium',\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=t3_endpoint_name\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ T3 endpoint deployed: {t3_endpoint_name}\")\n",
    "print(f\"üí∞ Cost: $0.05/hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Deploy Model on ml.m5.large\n",
    "\n",
    "**Key Learning:** M-series instances work for BOTH training and endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy to M5 endpoint\n",
    "m5_endpoint_name = f\"credit-risk-m5-{int(time.time())}\"\n",
    "print(f\"Deploying to {m5_endpoint_name}...\")\n",
    "\n",
    "m5_predictor = sklearn_model.deploy(\n",
    "    instance_type='ml.m5.large',\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=m5_endpoint_name\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ M5 endpoint deployed: {m5_endpoint_name}\")\n",
    "print(f\"üí∞ Cost: $0.115/hour (2.3x more expensive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_data = {\n",
    "    'credit_score': 720,\n",
    "    'income': 75000,\n",
    "    'debt_ratio': 0.35,\n",
    "    'employment_years': 5\n",
    "}\n",
    "\n",
    "# Test T3 endpoint\n",
    "print(\"Testing T3 endpoint...\")\n",
    "t3_latencies = []\n",
    "for i in range(100):\n",
    "    start = time.time()\n",
    "    result = t3_predictor.predict(test_data)\n",
    "    latency = (time.time() - start) * 1000\n",
    "    t3_latencies.append(latency)\n",
    "\n",
    "# Test M5 endpoint\n",
    "print(\"Testing M5 endpoint...\")\n",
    "m5_latencies = []\n",
    "for i in range(100):\n",
    "    start = time.time()\n",
    "    result = m5_predictor.predict(test_data)\n",
    "    latency = (time.time() - start) * 1000\n",
    "    m5_latencies.append(latency)\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nüìä Performance Comparison:\")\n",
    "print(f\"T3 - P50: {np.percentile(t3_latencies, 50):.2f}ms, P95: {np.percentile(t3_latencies, 95):.2f}ms\")\n",
    "print(f\"M5 - P50: {np.percentile(m5_latencies, 50):.2f}ms, P95: {np.percentile(m5_latencies, 95):.2f}ms\")\n",
    "\n",
    "# Cost per 1M requests\n",
    "t3_cost_per_1m = (0.05 / 3600) * (np.mean(t3_latencies) / 1000) * 1000000\n",
    "m5_cost_per_1m = (0.115 / 3600) * (np.mean(m5_latencies) / 1000) * 1000000\n",
    "\n",
    "print(f\"\\nüí∞ Cost per 1M requests:\")\n",
    "print(f\"T3: ${t3_cost_per_1m:.2f}\")\n",
    "print(f\"M5: ${m5_cost_per_1m:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: CloudWatch Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudwatch = boto3.client('cloudwatch', region_name=region)\n",
    "\n",
    "def get_endpoint_metrics(endpoint_name, metric_name):\n",
    "    response = cloudwatch.get_metric_statistics(\n",
    "        Namespace='AWS/SageMaker',\n",
    "        MetricName=metric_name,\n",
    "        Dimensions=[{'Name': 'EndpointName', 'Value': endpoint_name}],\n",
    "        StartTime=time.time() - 600,\n",
    "        EndTime=time.time(),\n",
    "        Period=300,\n",
    "        Statistics=['Average']\n",
    "    )\n",
    "    if response['Datapoints']:\n",
    "        return response['Datapoints'][0]['Average']\n",
    "    return 0\n",
    "\n",
    "# Get metrics\n",
    "print(\"üìà CloudWatch Metrics:\")\n",
    "print(f\"\\nT3 Endpoint ({t3_endpoint_name}):\")\n",
    "print(f\"  CPU Utilization: {get_endpoint_metrics(t3_endpoint_name, 'CPUUtilization'):.2f}%\")\n",
    "print(f\"  Memory Utilization: {get_endpoint_metrics(t3_endpoint_name, 'MemoryUtilization'):.2f}%\")\n",
    "\n",
    "print(f\"\\nM5 Endpoint ({m5_endpoint_name}):\")\n",
    "print(f\"  CPU Utilization: {get_endpoint_metrics(m5_endpoint_name, 'CPUUtilization'):.2f}%\")\n",
    "print(f\"  Memory Utilization: {get_endpoint_metrics(m5_endpoint_name, 'MemoryUtilization'):.2f}%\")\n",
    "\n",
    "print(\"\\nüí° Right-sizing Recommendation:\")\n",
    "print(\"Target: 50-70% CPU utilization for optimal cost/performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Cost Analysis & Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: 10,000 requests/day\n",
    "daily_requests = 10000\n",
    "avg_latency_t3 = np.mean(t3_latencies) / 1000  # seconds\n",
    "avg_latency_m5 = np.mean(m5_latencies) / 1000  # seconds\n",
    "\n",
    "# Calculate daily costs\n",
    "t3_daily_cost = 0.05 * 24  # Always running\n",
    "m5_daily_cost = 0.115 * 24\n",
    "\n",
    "# Monthly costs\n",
    "t3_monthly = t3_daily_cost * 30\n",
    "m5_monthly = m5_daily_cost * 30\n",
    "\n",
    "print(\"üí∞ Cost Analysis (10,000 requests/day):\")\n",
    "print(f\"\\nT3 Medium:\")\n",
    "print(f\"  Daily: ${t3_daily_cost:.2f}\")\n",
    "print(f\"  Monthly: ${t3_monthly:.2f}\")\n",
    "print(f\"  Latency: {avg_latency_t3*1000:.2f}ms\")\n",
    "\n",
    "print(f\"\\nM5 Large:\")\n",
    "print(f\"  Daily: ${m5_daily_cost:.2f}\")\n",
    "print(f\"  Monthly: ${m5_monthly:.2f}\")\n",
    "print(f\"  Latency: {avg_latency_m5*1000:.2f}ms\")\n",
    "\n",
    "print(f\"\\nüìä Decision Framework:\")\n",
    "print(f\"  Savings with T3: ${m5_monthly - t3_monthly:.2f}/month ({((m5_monthly - t3_monthly)/m5_monthly*100):.1f}%)\")\n",
    "print(f\"  ‚úÖ Use T3 if: Dev/test, low traffic, cost-sensitive\")\n",
    "print(f\"  ‚úÖ Use M5 if: Production, high traffic, latency-sensitive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoints\n",
    "print(\"Cleaning up endpoints...\")\n",
    "t3_predictor.delete_endpoint()\n",
    "m5_predictor.delete_endpoint()\n",
    "print(\"‚úÖ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "1. **T-series instances:**\n",
    "   - ‚úÖ ONLY for endpoints (NOT training)\n",
    "   - ‚úÖ Lowest cost ($0.05/hour)\n",
    "   - ‚úÖ Good for dev/test and low-traffic\n",
    "   - ‚ö†Ô∏è Burstable performance\n",
    "\n",
    "2. **M-series instances:**\n",
    "   - ‚úÖ For BOTH training and endpoints\n",
    "   - ‚úÖ Consistent performance\n",
    "   - ‚úÖ Good for production\n",
    "   - ‚ö†Ô∏è 2-3x more expensive\n",
    "\n",
    "3. **Right-sizing:**\n",
    "   - Monitor CloudWatch metrics\n",
    "   - Target 50-70% CPU utilization\n",
    "   - Balance cost vs performance\n",
    "   - Use auto-scaling for variable traffic\n",
    "\n",
    "4. **Cost optimization:**\n",
    "   - Start with smallest instance\n",
    "   - Scale up only if needed\n",
    "   - Use Spot instances for training (70% savings)\n",
    "   - Delete unused endpoints immediately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
