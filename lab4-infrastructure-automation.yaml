AWSTemplateFormatVersion: '2010-09-09'
Description: 'Lab 4: SecureBank Complete Infrastructure Automation with Document Processing'

Parameters:
  BankName:
    Type: String
    Description: 'Bank name for resource naming'
    Default: 'SecureBank'
    AllowedPattern: '^[a-zA-Z][a-zA-Z0-9]*$'
  
  Environment:
    Type: String
    Description: 'Environment name'
    Default: 'dev'
    AllowedValues: ['dev', 'staging', 'prod']
  
  AlertEmail:
    Type: String
    Description: 'Email for operational alerts'
    Default: 'ops@securebank.com'
    AllowedPattern: '^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'

  VPCStackName:
    Type: String
    Description: 'Name of the VPC CloudFormation stack'
    Default: 'SecureBank-dev-VPC'

Conditions:
  IsProduction: !Equals [!Ref Environment, 'prod']

Resources:
  # ============================================================================
  # S3 BUCKETS FOR BANKING DOCUMENTS
  # ============================================================================
  
  # Primary document storage bucket
  DocumentsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-documents-${AWS::AccountId}'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: 'DocumentRetentionPolicy'
            Status: Enabled
            ExpirationInDays: !If [IsProduction, 2555, 90]  # 7 years for prod, 90 days for dev
            NoncurrentVersionExpirationInDays: 30
          - Id: 'IntelligentTiering'
            Status: Enabled
            Transitions:
              - TransitionInDays: 30
                StorageClass: STANDARD_IA
              - TransitionInDays: 90
                StorageClass: GLACIER
              - TransitionInDays: 365
                StorageClass: DEEP_ARCHIVE
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: DataClassification
          Value: 'Confidential'
        - Key: RetentionPeriod
          Value: !If [IsProduction, '7-years', '90-days']
        - Key: Purpose
          Value: 'Banking Document Storage'

  # Processed documents bucket
  ProcessedDocumentsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-processed-${AWS::AccountId}'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: DataClassification
          Value: 'Internal'
        - Key: Purpose
          Value: 'Processed Banking Documents'

  # Audit logs bucket
  AuditLogsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-audit-logs-${AWS::AccountId}'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: 'AuditLogRetention'
            Status: Enabled
            ExpirationInDays: !If [IsProduction, 2555, 365]  # 7 years for prod, 1 year for dev
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: DataClassification
          Value: 'Restricted'
        - Key: Purpose
          Value: 'Audit and Compliance Logs'

  # ============================================================================
  # LAMBDA FUNCTION FOR DOCUMENT PROCESSING
  # ============================================================================
  
  # IAM Role for Lambda Function
  DocumentProcessingRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${BankName}-${Environment}-DocumentProcessingRole'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: DocumentProcessingPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:PutObject'
                  - 's3:DeleteObject'
                Resource:
                  - !Sub '${DocumentsBucket.Arn}/*'
                  - !Sub '${ProcessedDocumentsBucket.Arn}/*'
                  - !Sub '${AuditLogsBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - 's3:ListBucket'
                Resource:
                  - !GetAtt DocumentsBucket.Arn
                  - !GetAtt ProcessedDocumentsBucket.Arn
                  - !GetAtt AuditLogsBucket.Arn
              - Effect: Allow
                Action:
                  - 'textract:*'
                  - 'comprehend:*'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: '*'
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Purpose
          Value: 'Document Processing'
  
  DocumentProcessingFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${BankName}-${Environment}-DocumentProcessor'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt DocumentProcessingRole.Arn
      Timeout: 300
      MemorySize: 1024
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          DOCUMENTS_BUCKET: !Ref DocumentsBucket
          PROCESSED_BUCKET: !Ref ProcessedDocumentsBucket
          AUDIT_BUCKET: !Ref AuditLogsBucket
          BANK_NAME: !Ref BankName
      Code:
        ZipFile: |
          import json
          import boto3
          import logging
          import os
          from datetime import datetime
          import uuid
          
          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          
          # Initialize AWS clients
          textract = boto3.client('textract')
          comprehend = boto3.client('comprehend')
          s3 = boto3.client('s3')
          
          def lambda_handler(event, context):
              """
              SecureBank Document Processing Function
              Processes banking documents using AWS AI services with compliance logging
              """
              
              try:
                  # Extract S3 event information
                  for record in event['Records']:
                      bucket = record['s3']['bucket']['name']
                      key = record['s3']['object']['key']
                      
                      logger.info(f"Processing document: {bucket}/{key}")
                      
                      # Generate processing ID for audit trail
                      processing_id = str(uuid.uuid4())
                      
                      # Extract text using Textract
                      textract_response = textract.detect_document_text(
                          Document={
                              'S3Object': {
                                  'Bucket': bucket,
                                  'Name': key
                              }
                          }
                      )
                      
                      # Extract text content
                      extracted_text = ""
                      confidence_scores = []
                      
                      for block in textract_response['Blocks']:
                          if block['BlockType'] == 'LINE':
                              extracted_text += block['Text'] + "\n"
                              confidence_scores.append(block['Confidence'])
                      
                      # Calculate average confidence
                      avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
                      
                      # Analyze document with Comprehend for banking-specific insights
                      comprehend_response = comprehend.detect_entities(
                          Text=extracted_text[:5000],  # Comprehend has text limits
                          LanguageCode='en'
                      )
                      
                      # Extract banking-relevant entities
                      banking_entities = []
                      for entity in comprehend_response['Entities']:
                          if entity['Type'] in ['PERSON', 'ORGANIZATION', 'LOCATION', 'OTHER']:
                              banking_entities.append({
                                  'Text': entity['Text'],
                                  'Type': entity['Type'],
                                  'Confidence': entity['Score']
                              })
                      
                      # Sentiment analysis for risk assessment
                      sentiment_response = comprehend.detect_sentiment(
                          Text=extracted_text[:5000],
                          LanguageCode='en'
                      )
                      
                      # Create processing results
                      processing_results = {
                          'processing_id': processing_id,
                          'timestamp': datetime.utcnow().isoformat(),
                          'source_document': {
                              'bucket': bucket,
                              'key': key
                          },
                          'textract_results': {
                              'text_length': len(extracted_text),
                              'average_confidence': round(avg_confidence, 2),
                              'blocks_processed': len(textract_response['Blocks'])
                          },
                          'comprehend_results': {
                              'entities_found': len(banking_entities),
                              'entities': banking_entities[:10],  # Limit for storage
                              'sentiment': {
                                  'sentiment': sentiment_response['Sentiment'],
                                  'confidence': sentiment_response['SentimentScore']
                              }
                          },
                          'compliance_flags': {
                              'pii_detected': len([e for e in banking_entities if e['Type'] == 'PERSON']) > 0,
                              'low_confidence_text': avg_confidence < 80,
                              'requires_manual_review': avg_confidence < 70 or sentiment_response['Sentiment'] == 'NEGATIVE'
                          }
                      }
                      
                      # Store processed results
                      processed_key = f"processed/{datetime.utcnow().strftime('%Y/%m/%d')}/{processing_id}.json"
                      s3.put_object(
                          Bucket=os.environ['PROCESSED_BUCKET'],
                          Key=processed_key,
                          Body=json.dumps(processing_results, indent=2),
                          ServerSideEncryption='AES256',
                          Metadata={
                              'processing-id': processing_id,
                              'source-document': key,
                              'confidence-score': str(avg_confidence),
                              'requires-review': str(processing_results['compliance_flags']['requires_manual_review'])
                          }
                      )
                      
                      # Create audit log entry
                      audit_entry = {
                          'event_type': 'document_processed',
                          'processing_id': processing_id,
                          'timestamp': datetime.utcnow().isoformat(),
                          'user_identity': context.invoked_function_arn,
                          'source_ip': 'lambda-internal',
                          'document_info': {
                              'bucket': bucket,
                              'key': key,
                              'size_bytes': record['s3']['object'].get('size', 0)
                          },
                          'processing_summary': {
                              'confidence_score': avg_confidence,
                              'entities_detected': len(banking_entities),
                              'sentiment': sentiment_response['Sentiment'],
                              'requires_review': processing_results['compliance_flags']['requires_manual_review']
                          },
                          'compliance_status': 'processed'
                      }
                      
                      # Store audit log
                      audit_key = f"audit-logs/{datetime.utcnow().strftime('%Y/%m/%d')}/{processing_id}-audit.json"
                      s3.put_object(
                          Bucket=os.environ['AUDIT_BUCKET'],
                          Key=audit_key,
                          Body=json.dumps(audit_entry, indent=2),
                          ServerSideEncryption='AES256'
                      )
                      
                      logger.info(f"Document processing completed successfully. Processing ID: {processing_id}")
                      
                      # Send notification if manual review required
                      if processing_results['compliance_flags']['requires_manual_review']:
                          logger.warning(f"Document {key} requires manual review. Processing ID: {processing_id}")
                          # Here you would typically send an SNS notification
                      
              except Exception as e:
                  logger.error(f"Error processing document: {str(e)}")
                  
                  # Create error audit log
                  error_audit = {
                      'event_type': 'document_processing_error',
                      'timestamp': datetime.utcnow().isoformat(),
                      'error_message': str(e),
                      'document_info': {
                          'bucket': bucket if 'bucket' in locals() else 'unknown',
                          'key': key if 'key' in locals() else 'unknown'
                      },
                      'compliance_status': 'error'
                  }
                  
                  try:
                      s3.put_object(
                          Bucket=os.environ['AUDIT_BUCKET'],
                          Key=f"error-logs/{datetime.utcnow().strftime('%Y/%m/%d')}/{uuid.uuid4()}-error.json",
                          Body=json.dumps(error_audit, indent=2),
                          ServerSideEncryption='AES256'
                      )
                  except:
                      pass  # Don't fail if we can't log the error
                  
                  raise
              
              return {
                  'statusCode': 200,
                  'body': json.dumps({
                      'message': 'Document processing completed',
                      'processed_documents': len(event['Records'])
                  })
              }
      
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Purpose
          Value: 'Banking Document Processing'

  # Lambda permission for S3 to invoke the function
  DocumentProcessingPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DocumentProcessingFunction
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt DocumentsBucket.Arn

  # Custom resource to configure S3 bucket notification (avoids circular dependency)
  S3BucketNotificationConfiguration:
    Type: Custom::S3BucketNotification
    DependsOn: DocumentProcessingPermission
    Properties:
      ServiceToken: !GetAtt ConfigureS3NotificationFunction.Arn
      BucketName: !Ref DocumentsBucket
      LambdaFunctionArn: !GetAtt DocumentProcessingFunction.Arn
      NotificationConfiguration:
        LambdaFunctionConfigurations:
          - Events:
              - 's3:ObjectCreated:*'
            LambdaFunctionArn: !GetAtt DocumentProcessingFunction.Arn
            Filter:
              Key:
                FilterRules:
                  - Name: prefix
                    Value: 'incoming/'
                  - Name: suffix
                    Value: '.pdf'

  # Lambda function to configure S3 bucket notifications
  ConfigureS3NotificationFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${BankName}-${Environment}-ConfigureS3Notification'
      Runtime: python3.11
      Handler: index.handler
      Role: !GetAtt ConfigureS3NotificationRole.Arn
      Timeout: 60
      Code:
        ZipFile: |
          import json
          import boto3
          import cfnresponse
          
          s3 = boto3.client('s3')
          
          def handler(event, context):
              try:
                  bucket_name = event['ResourceProperties']['BucketName']
                  lambda_arn = event['ResourceProperties']['LambdaFunctionArn']
                  
                  if event['RequestType'] == 'Delete':
                      # Remove notification configuration
                      s3.put_bucket_notification_configuration(
                          Bucket=bucket_name,
                          NotificationConfiguration={}
                      )
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                      return
                  
                  # Configure notification
                  notification_config = {
                      'LambdaFunctionConfigurations': [
                          {
                              'LambdaFunctionArn': lambda_arn,
                              'Events': ['s3:ObjectCreated:*'],
                              'Filter': {
                                  'Key': {
                                      'FilterRules': [
                                          {'Name': 'prefix', 'Value': 'incoming/'},
                                          {'Name': 'suffix', 'Value': '.pdf'}
                                      ]
                                  }
                              }
                          }
                      ]
                  }
                  
                  s3.put_bucket_notification_configuration(
                      Bucket=bucket_name,
                      NotificationConfiguration=notification_config
                  )
                  
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e)})

  # IAM role for the configuration Lambda
  ConfigureS3NotificationRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3NotificationPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutBucketNotification
                  - s3:GetBucketNotification
                Resource: !GetAtt DocumentsBucket.Arn

  # ============================================================================
  # CLOUDWATCH MONITORING AND ALARMS
  # ============================================================================
  
  # SNS Topic for operational alerts
  OperationalAlertsTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub '${BankName}-${Environment}-OperationalAlerts'
      DisplayName: 'SecureBank Operational Alerts'
      Subscription:
        - Protocol: email
          Endpoint: !Ref AlertEmail

  # Lambda function errors alarm
  LambdaErrorsAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${BankName}-${Environment}-Lambda-Errors'
      AlarmDescription: 'Alert when Lambda function has errors'
      MetricName: Errors
      Namespace: AWS/Lambda
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref DocumentProcessingFunction
      AlarmActions:
        - !Ref OperationalAlertsTopic

  # Lambda function duration alarm
  LambdaDurationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${BankName}-${Environment}-Lambda-Duration'
      AlarmDescription: 'Alert when Lambda function duration is high'
      MetricName: Duration
      Namespace: AWS/Lambda
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 240000  # 4 minutes (function timeout is 5 minutes)
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref DocumentProcessingFunction
      AlarmActions:
        - !Ref OperationalAlertsTopic

  # S3 bucket size monitoring
  S3BucketSizeAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${BankName}-${Environment}-S3-BucketSize'
      AlarmDescription: 'Alert when S3 bucket size exceeds threshold'
      MetricName: BucketSizeBytes
      Namespace: AWS/S3
      Statistic: Average
      Period: 86400  # Daily
      EvaluationPeriods: 1
      Threshold: 107374182400  # 100 GB
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: BucketName
          Value: !Ref DocumentsBucket
        - Name: StorageType
          Value: StandardStorage
      AlarmActions:
        - !Ref OperationalAlertsTopic

  # ============================================================================
  # CLOUDWATCH DASHBOARD
  # ============================================================================
  
  OperationalDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub '${BankName}-${Environment}-Operations'
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Lambda", "Invocations", "FunctionName", "${DocumentProcessingFunction}" ],
                  [ ".", "Errors", ".", "." ],
                  [ ".", "Duration", ".", "." ]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "${AWS::Region}",
                "title": "Document Processing Lambda Metrics"
              }
            },
            {
              "type": "metric",
              "x": 12,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/S3", "BucketSizeBytes", "BucketName", "${DocumentsBucket}", "StorageType", "StandardStorage" ],
                  [ ".", "NumberOfObjects", ".", ".", ".", "AllStorageTypes" ]
                ],
                "period": 86400,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "S3 Storage Metrics"
              }
            },
            {
              "type": "log",
              "x": 0,
              "y": 6,
              "width": 24,
              "height": 6,
              "properties": {
                "query": "SOURCE '/aws/lambda/${DocumentProcessingFunction}'\n| fields @timestamp, @message\n| filter @message like /ERROR/\n| sort @timestamp desc\n| limit 100",
                "region": "${AWS::Region}",
                "title": "Recent Lambda Errors"
              }
            }
          ]
        }

Outputs:
  DocumentsBucketName:
    Description: 'Name of the documents S3 bucket'
    Value: !Ref DocumentsBucket
    Export:
      Name: !Sub '${AWS::StackName}-DocumentsBucket'
  
  ProcessedDocumentsBucketName:
    Description: 'Name of the processed documents S3 bucket'
    Value: !Ref ProcessedDocumentsBucket
    Export:
      Name: !Sub '${AWS::StackName}-ProcessedDocumentsBucket'
  
  AuditLogsBucketName:
    Description: 'Name of the audit logs S3 bucket'
    Value: !Ref AuditLogsBucket
    Export:
      Name: !Sub '${AWS::StackName}-AuditLogsBucket'
  
  DocumentProcessingFunctionArn:
    Description: 'ARN of the document processing Lambda function'
    Value: !GetAtt DocumentProcessingFunction.Arn
    Export:
      Name: !Sub '${AWS::StackName}-DocumentProcessingFunction'
  
  OperationalDashboardURL:
    Description: 'URL to the operational dashboard'
    Value: !Sub 'https://${AWS::Region}.console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#dashboards:name=${BankName}-${Environment}-Operations'
  
  DeploymentInstructions:
    Description: 'Post-deployment steps'
    Value: |
      1. Upload test documents to the incoming/ folder in the documents bucket
      2. Monitor Lambda function execution in CloudWatch Logs
      3. Check processed results in the processed documents bucket
      4. Review audit logs for compliance tracking
      5. Set up additional monitoring and alerting as needed
      6. Configure backup and disaster recovery procedures