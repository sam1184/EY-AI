{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7 Lab 1: Amazon Comprehend - NLP for Banking\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand Amazon Comprehend capabilities\n",
    "- Perform sentiment analysis on customer feedback\n",
    "- Extract entities and key phrases\n",
    "- Detect language and PII\n",
    "- Build banking NLP applications\n",
    "\n",
    "## üè¶ Banking Use Case\n",
    "Analyze **customer feedback and reviews** to understand sentiment, extract insights, and improve banking services.\n",
    "\n",
    "## ‚è±Ô∏è Duration: 30 minutes\n",
    "## üí∞ Cost: ~$0.10 (Comprehend API calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "# Initialize Comprehend client\n",
    "comprehend = boto3.client('comprehend', region_name='us-east-1')\n",
    "\n",
    "print(\"‚úÖ Amazon Comprehend client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Feedback Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample customer feedback from SecureBank\n",
    "customer_feedback = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"text\": \"I absolutely love the new mobile banking app! It's so easy to transfer money and check my balance. The interface is intuitive and fast.\",\n",
    "        \"channel\": \"App Store Review\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"text\": \"Terrible experience at the branch today. Waited 45 minutes just to deposit a check. The staff was unhelpful and rude.\",\n",
    "        \"channel\": \"Survey\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"text\": \"The loan application process was straightforward. I applied online and got approved within 24 hours. Great service!\",\n",
    "        \"channel\": \"Email\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"text\": \"I'm disappointed with the high fees on my checking account. $15/month is too much compared to other banks.\",\n",
    "        \"channel\": \"Social Media\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"text\": \"The customer service team helped me resolve my issue quickly. They were professional and knowledgeable.\",\n",
    "        \"channel\": \"Phone Survey\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"text\": \"My credit card was declined at the store even though I had available credit. Very embarrassing situation.\",\n",
    "        \"channel\": \"Complaint\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìä Loaded {len(customer_feedback)} customer feedback items\\n\")\n",
    "for feedback in customer_feedback:\n",
    "    print(f\"ID {feedback['id']}: {feedback['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze sentiment using Amazon Comprehend\n",
    "    \"\"\"\n",
    "    response = comprehend.detect_sentiment(\n",
    "        Text=text,\n",
    "        LanguageCode='en'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'sentiment': response['Sentiment'],\n",
    "        'positive': response['SentimentScore']['Positive'],\n",
    "        'negative': response['SentimentScore']['Negative'],\n",
    "        'neutral': response['SentimentScore']['Neutral'],\n",
    "        'mixed': response['SentimentScore']['Mixed']\n",
    "    }\n",
    "\n",
    "# Analyze all feedback\n",
    "print(\"üîç Analyzing Sentiment...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "for feedback in customer_feedback:\n",
    "    sentiment = analyze_sentiment(feedback['text'])\n",
    "    \n",
    "    print(f\"\\nID {feedback['id']}: {feedback['channel']}\")\n",
    "    print(f\"Text: {feedback['text'][:80]}...\")\n",
    "    print(f\"\\nüìä Sentiment: {sentiment['sentiment']}\")\n",
    "    print(f\"  Positive: {sentiment['positive']:.2%}\")\n",
    "    print(f\"  Negative: {sentiment['negative']:.2%}\")\n",
    "    print(f\"  Neutral: {sentiment['neutral']:.2%}\")\n",
    "    print(f\"  Mixed: {sentiment['mixed']:.2%}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results.append({\n",
    "        'id': feedback['id'],\n",
    "        'channel': feedback['channel'],\n",
    "        'sentiment': sentiment['sentiment'],\n",
    "        'confidence': max(sentiment['positive'], sentiment['negative'], \n",
    "                         sentiment['neutral'], sentiment['mixed'])\n",
    "    })\n",
    "\n",
    "# Summary\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nüìà Sentiment Summary:\")\n",
    "print(df_results['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract entities (people, places, organizations, etc.)\n",
    "    \"\"\"\n",
    "    response = comprehend.detect_entities(\n",
    "        Text=text,\n",
    "        LanguageCode='en'\n",
    "    )\n",
    "    \n",
    "    entities = []\n",
    "    for entity in response['Entities']:\n",
    "        entities.append({\n",
    "            'text': entity['Text'],\n",
    "            'type': entity['Type'],\n",
    "            'score': entity['Score']\n",
    "        })\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Extract entities from sample feedback\n",
    "sample_text = \"\"\"John Smith applied for a $50,000 personal loan at SecureBank's \n",
    "New York branch on January 15, 2024. He works at Microsoft and earns $120,000 annually.\"\"\"\n",
    "\n",
    "print(\"üîç Extracting Entities...\\n\")\n",
    "print(f\"Text: {sample_text}\\n\")\n",
    "\n",
    "entities = extract_entities(sample_text)\n",
    "\n",
    "print(\"üìä Extracted Entities:\\n\")\n",
    "for entity in entities:\n",
    "    print(f\"  {entity['type']:15} | {entity['text']:20} | Confidence: {entity['score']:.2%}\")\n",
    "\n",
    "# Entity types\n",
    "print(\"\\nüí° Entity Types Detected:\")\n",
    "entity_types = set([e['type'] for e in entities])\n",
    "for etype in entity_types:\n",
    "    count = len([e for e in entities if e['type'] == etype])\n",
    "    print(f\"  - {etype}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Key Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_phrases(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract key phrases from text\n",
    "    \"\"\"\n",
    "    response = comprehend.detect_key_phrases(\n",
    "        Text=text,\n",
    "        LanguageCode='en'\n",
    "    )\n",
    "    \n",
    "    phrases = []\n",
    "    for phrase in response['KeyPhrases']:\n",
    "        phrases.append({\n",
    "            'text': phrase['Text'],\n",
    "            'score': phrase['Score']\n",
    "        })\n",
    "    \n",
    "    return sorted(phrases, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Extract key phrases from positive feedback\n",
    "positive_feedback = customer_feedback[0]['text']\n",
    "\n",
    "print(\"üîë Extracting Key Phrases...\\n\")\n",
    "print(f\"Text: {positive_feedback}\\n\")\n",
    "\n",
    "key_phrases = extract_key_phrases(positive_feedback)\n",
    "\n",
    "print(\"üìä Key Phrases (Top 10):\\n\")\n",
    "for i, phrase in enumerate(key_phrases[:10], 1):\n",
    "    print(f\"  {i}. {phrase['text']:30} | Confidence: {phrase['score']:.2%}\")\n",
    "\n",
    "print(\"\\nüí° Use Case: Identify common themes in customer feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: PII Detection (Personally Identifiable Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pii(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Detect PII in text for compliance\n",
    "    \"\"\"\n",
    "    response = comprehend.detect_pii_entities(\n",
    "        Text=text,\n",
    "        LanguageCode='en'\n",
    "    )\n",
    "    \n",
    "    pii_entities = []\n",
    "    for entity in response['Entities']:\n",
    "        pii_entities.append({\n",
    "            'type': entity['Type'],\n",
    "            'score': entity['Score'],\n",
    "            'begin': entity['BeginOffset'],\n",
    "            'end': entity['EndOffset']\n",
    "        })\n",
    "    \n",
    "    return pii_entities\n",
    "\n",
    "# Sample text with PII\n",
    "pii_text = \"\"\"Customer John Doe (SSN: 123-45-6789) called from phone number 555-123-4567. \n",
    "His email is john.doe@email.com and he lives at 123 Main Street, New York, NY 10001. \n",
    "His credit card ending in 4532 was used for the transaction.\"\"\"\n",
    "\n",
    "print(\"üîí Detecting PII...\\n\")\n",
    "print(f\"Text: {pii_text}\\n\")\n",
    "\n",
    "pii_entities = detect_pii(pii_text)\n",
    "\n",
    "print(\"‚ö†Ô∏è PII Detected:\\n\")\n",
    "for pii in pii_entities:\n",
    "    extracted_text = pii_text[pii['begin']:pii['end']]\n",
    "    print(f\"  {pii['type']:20} | {extracted_text:25} | Confidence: {pii['score']:.2%}\")\n",
    "\n",
    "print(\"\\nüí° Use Case: Redact PII before storing customer feedback\")\n",
    "print(\"\\nüîê Compliance: GDPR, CCPA, PCI-DSS require PII protection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Detect dominant language in text\n",
    "    \"\"\"\n",
    "    response = comprehend.detect_dominant_language(Text=text)\n",
    "    \n",
    "    languages = []\n",
    "    for lang in response['Languages']:\n",
    "        languages.append({\n",
    "            'code': lang['LanguageCode'],\n",
    "            'score': lang['Score']\n",
    "        })\n",
    "    \n",
    "    return sorted(languages, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Multi-language feedback\n",
    "multilingual_feedback = [\n",
    "    \"I love this bank! Great service.\",\n",
    "    \"Me encanta este banco. Excelente servicio.\",\n",
    "    \"J'adore cette banque. Service excellent.\",\n",
    "    \"Ich liebe diese Bank. Toller Service.\"\n",
    "]\n",
    "\n",
    "print(\"üåç Detecting Languages...\\n\")\n",
    "\n",
    "for text in multilingual_feedback:\n",
    "    languages = detect_language(text)\n",
    "    primary = languages[0]\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"  Language: {primary['code'].upper()} (Confidence: {primary['score']:.2%})\\n\")\n",
    "\n",
    "print(\"üí° Use Case: Route feedback to appropriate language support team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Banking Insights Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all feedback comprehensively\n",
    "print(\"üìä SecureBank Customer Feedback Analysis Dashboard\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sentiment breakdown\n",
    "sentiment_counts = df_results['sentiment'].value_counts()\n",
    "total = len(df_results)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Sentiment Distribution:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / total) * 100\n",
    "    bar = '‚ñà' * int(percentage / 5)\n",
    "    print(f\"  {sentiment:10} | {bar:20} | {count}/{total} ({percentage:.1f}%)\")\n",
    "\n",
    "# Channel analysis\n",
    "print(\"\\n2Ô∏è‚É£ Feedback by Channel:\")\n",
    "channel_sentiment = df_results.groupby(['channel', 'sentiment']).size().unstack(fill_value=0)\n",
    "print(channel_sentiment)\n",
    "\n",
    "# Action items\n",
    "print(\"\\n3Ô∏è‚É£ Recommended Actions:\")\n",
    "negative_count = sentiment_counts.get('NEGATIVE', 0)\n",
    "positive_count = sentiment_counts.get('POSITIVE', 0)\n",
    "\n",
    "if negative_count > 0:\n",
    "    print(f\"  ‚ö†Ô∏è {negative_count} negative feedback items require immediate attention\")\n",
    "    print(\"     - Review complaints and identify root causes\")\n",
    "    print(\"     - Contact customers for resolution\")\n",
    "    print(\"     - Implement process improvements\")\n",
    "\n",
    "if positive_count > 0:\n",
    "    print(f\"  ‚úÖ {positive_count} positive feedback items\")\n",
    "    print(\"     - Share success stories with team\")\n",
    "    print(\"     - Identify best practices to replicate\")\n",
    "    print(\"     - Use in marketing materials\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Key Metrics:\")\n",
    "print(f\"  Customer Satisfaction Score: {(positive_count / total * 100):.1f}%\")\n",
    "print(f\"  Response Required: {negative_count} items\")\n",
    "print(f\"  Average Confidence: {df_results['confidence'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Production Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè≠ Production Use Cases for Amazon Comprehend in Banking:\\n\")\n",
    "\n",
    "use_cases = {\n",
    "    \"Use Case\": [\n",
    "        \"Customer Feedback Analysis\",\n",
    "        \"Complaint Prioritization\",\n",
    "        \"Fraud Detection\",\n",
    "        \"Loan Application Processing\",\n",
    "        \"Compliance Monitoring\",\n",
    "        \"Chatbot Intent Detection\"\n",
    "    ],\n",
    "    \"Comprehend Feature\": [\n",
    "        \"Sentiment Analysis\",\n",
    "        \"Sentiment + Key Phrases\",\n",
    "        \"Entity Extraction\",\n",
    "        \"Entity + PII Detection\",\n",
    "        \"PII Detection\",\n",
    "        \"Key Phrases + Entities\"\n",
    "    ],\n",
    "    \"Business Impact\": [\n",
    "        \"Improve customer satisfaction\",\n",
    "        \"Faster response times\",\n",
    "        \"Reduce fraud losses\",\n",
    "        \"Automate document review\",\n",
    "        \"Ensure regulatory compliance\",\n",
    "        \"Better customer service\"\n",
    "    ],\n",
    "    \"Cost Savings\": [\n",
    "        \"$50K/year\",\n",
    "        \"$30K/year\",\n",
    "        \"$200K/year\",\n",
    "        \"$100K/year\",\n",
    "        \"Avoid fines\",\n",
    "        \"$40K/year\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_use_cases = pd.DataFrame(use_cases)\n",
    "print(df_use_cases.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí∞ Cost Analysis:\")\n",
    "print(\"  - Comprehend: $0.0001 per unit (100 characters)\")\n",
    "print(\"  - 1M customer feedback items: ~$100\")\n",
    "print(\"  - Manual analysis cost: ~$50,000\")\n",
    "print(\"  - ROI: 500x\")\n",
    "\n",
    "print(\"\\n‚ö° Performance:\")\n",
    "print(\"  - Latency: < 100ms per request\")\n",
    "print(\"  - Throughput: 1000s of requests/second\")\n",
    "print(\"  - Accuracy: 90-95% for sentiment\")\n",
    "print(\"  - Languages: 100+ supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÖ Lab 1 Complete: Amazon Comprehend NLP\\n\")\n",
    "print(\"üéì What You Learned:\")\n",
    "print(\"  1. Sentiment analysis for customer feedback\")\n",
    "print(\"  2. Entity extraction (people, places, organizations)\")\n",
    "print(\"  3. Key phrase extraction for themes\")\n",
    "print(\"  4. PII detection for compliance\")\n",
    "print(\"  5. Language detection for routing\")\n",
    "print(\"  6. Building insights dashboards\")\n",
    "print(\"\\nüí° Key Takeaways:\")\n",
    "print(\"  - Comprehend is serverless and fully managed\")\n",
    "print(\"  - No ML expertise required\")\n",
    "print(\"  - Pay only for what you use\")\n",
    "print(\"  - Scales automatically\")\n",
    "print(\"  - 100+ languages supported\")\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  - Integrate with your feedback systems\")\n",
    "print(\"  - Set up automated analysis pipelines\")\n",
    "print(\"  - Build real-time dashboards\")\n",
    "print(\"  - Implement PII redaction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
